{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "traffic_signs.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9TMM5eYRKUj",
        "outputId": "ad95172b-aa41-4c3c-be3b-8f723d6b6202"
      },
      "source": [
        "# Using ! to invoke the following shell command inside our notebook\n",
        "!git clone https://bitbucket.org/jadslim/german-traffic-signs"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'german-traffic-signs'...\n",
            "Unpacking objects: 100% (6/6), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W10rtUtZVUBf",
        "outputId": "74ee1fef-421c-4eef-f71f-e65a9325b87e"
      },
      "source": [
        "# The above cell cloned the data from the bitbucket server and created a folder\n",
        "# called \"german-traffic-sign\". Now we list the data inside this folder\n",
        "!ls german-traffic-signs/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "signnames.csv  test.p  train.p\tvalid.p\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6rLYMm_XKqz"
      },
      "source": [
        "As it can be seen there are 4 files. First one is a spreadsheet of sign name, and the other 3 files are pickle files, that contain our respective training, test and validation datasets.\n",
        "\n",
        "In python to save something on disk, it can be pickled. That is it can be serialized before writing it to file. By serializing it, it converts all the object to a character stream.\n",
        "\n",
        "Pickled file contain serialized data that can be unpickled when desired"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIke2fMYQBUB"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Dropout, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "import pickle"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74WN-qA7RINA"
      },
      "source": [
        "np.random.seed(0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZPlZuphlRTJ"
      },
      "source": [
        "# with keyword is used whenever we wish to execute two operations as a pair and\n",
        "# invoke a block of code in between\n",
        "# Here using \"with\", we will open a file, manipulate it and \"with\" will then\n",
        "# automatically close the file.\n",
        "with open('german-traffic-signs/train.p', 'rb') as f:\n",
        "    train_data = pickle.load(f)\n",
        "with open('german-traffic-signs/valid.p', 'rb') as f:\n",
        "    val_data = pickle.load(f)\n",
        "with open('german-traffic-signs/test.p', 'rb') as f:\n",
        "    test_data = pickle.load(f)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv9_LCB9w96z"
      },
      "source": [
        "if we print the type of our pickled datasets using\n",
        "```\n",
        "print(type(train_data))\n",
        "```\n",
        "we can see they are of type\n",
        "```\n",
        "<class 'dict'>\n",
        "```\n",
        "From the key value pairs of these dictionaries, two values are of our interest. One of them is *features*, and the other one is *labels*.\n",
        "\n",
        "Feature key corresponds to values of training images in pixel representation, wherese the labels corresponds to an array of labels, which pretty much label each training image as belonging to some class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBZ71Druwxuo"
      },
      "source": [
        "X_train, y_train = train_data['features'], train_data['labels']\n",
        "X_val, y_val = val_data['features'], val_data['labels']\n",
        "X_test, y_test = test_data['features'], test_data['labels']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JfX22WMyxJz",
        "outputId": "9a54f90c-7449-4d90-b152-2da106b3fe99"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(34799, 32, 32, 3)\n",
            "(4410, 32, 32, 3)\n",
            "(12630, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkreY_34zOKd"
      },
      "source": [
        "As it can be seen, we have roughly 35000 training images of size 32 by 32 pixels with depth of 3 (as our traffic signs despite the MNIST datasets are in RGB format, they have a depth of 3 for each of the 3 color channels: Red, Green and Blue).\n",
        "\n",
        "Similarly, there are about 4500 validation and 12500 testing images.\n",
        "\n",
        "We checked it here to make sure that they are consistent and are based on our expectations.\n",
        "\n",
        "As we have imported these data from a repository, it is a good practice to verify that our dataset was imported correctly whenever our program is running."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GomgGZIAy7xe"
      },
      "source": [
        "# Assert that the number of images equal to the number of labels.\n",
        "assert(X_train.shape[0] == y_train.shape[0]), \"The number of images is not equal to the number of labels\"\n",
        "assert(X_val.shape[0] == y_val.shape[0]), \"The number of images is not equal to the number of labels\"\n",
        "assert(X_test.shape[0] == y_test.shape[0]), \"The number of images is not equal to the number of labels\"\n",
        "\n",
        "assert(X_train.shape[1:] == (32, 32, 3)), \"The dimension of the images are not 32 x 32 x 3\"\n",
        "assert(X_val.shape[1:] == (32, 32, 3)), \"The dimension of the images are not 32 x 32 x 3\"\n",
        "assert(X_test.shape[1:] == (32, 32, 3)), \"The dimension of the images are not 32 x 32 x 3\""
      ],
      "execution_count": 15,
      "outputs": []
    }
  ]
}