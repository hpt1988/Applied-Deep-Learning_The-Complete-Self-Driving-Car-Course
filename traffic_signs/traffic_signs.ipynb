{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "traffic_signs.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9TMM5eYRKUj",
        "outputId": "ad95172b-aa41-4c3c-be3b-8f723d6b6202"
      },
      "source": [
        "# Using ! to invoke the following shell command inside our notebook\n",
        "!git clone https://bitbucket.org/jadslim/german-traffic-signs"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'german-traffic-signs'...\n",
            "Unpacking objects: 100% (6/6), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W10rtUtZVUBf",
        "outputId": "74ee1fef-421c-4eef-f71f-e65a9325b87e"
      },
      "source": [
        "# The above cell cloned the data from the bitbucket server and created a folder\n",
        "# called \"german-traffic-sign\". Now we list the data inside this folder\n",
        "!ls german-traffic-signs/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "signnames.csv  test.p  train.p\tvalid.p\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6rLYMm_XKqz"
      },
      "source": [
        "As it can be seen there are 4 files. First one is a spreadsheet of sign name, and the other 3 files are pickle files, that contain our respective training, test and validation datasets.\n",
        "\n",
        "In python to save something on disk, it can be pickled. That is it can be serialized before writing it to file. By serializing it, it converts all the object to a character stream.\n",
        "\n",
        "Pickled file contain serialized data that can be unpickled when desired"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIke2fMYQBUB"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Dropout, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74WN-qA7RINA"
      },
      "source": [
        "np.random.seed(0)"
      ],
      "execution_count": 2,
      "outputs": []
    }
  ]
}